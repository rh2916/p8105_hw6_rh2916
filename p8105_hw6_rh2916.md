p8105\_hw6\_rh2916
================
Rui Huang
November 16, 2018

## Problem 1

### Tidy data for analysis

``` r
df_homicide = read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(city_state = paste(city, state, sep = ","),
         solving_status = ifelse(disposition == "Closed by arrest", 1, 0),
         victim_age = as.numeric(victim_age)) %>% 
  filter(city_state != "Dallas,TX" & city_state != "Phoenix,AZ" & city_state != "Kansas City,MO" & city_state != "Tulsa,AL") %>%
  mutate(victim_race = ifelse(victim_race == "White", "white","non_white"),
         victim_race = fct_relevel(victim_race,"white", "non_white"))
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_integer(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

    ## Warning in evalq(as.numeric(victim_age), <environment>): NAs introduced by
    ## coercion

After cleaning and tidying, the dataset contains 14 variables and 48507
observations.

### Fit regression for Baltimore,MD

The logistic regression is fitted by glm with resolved vs unresolved as
the outcome and victim victim\_age, victim\_sex and victim\_race as
predictors.

``` r
Baltimore_homicide =
  df_homicide %>% 
  filter(city_state == "Baltimore,MD") 
  
glm_solving_status = 
  Baltimore_homicide %>% 
  glm(solving_status ~ victim_age + victim_race + victim_sex, data = ., family = binomial()) 

glm_solving_status %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         log_OR = estimate,
         OR_lower = exp(estimate - std.error * 1.96),
         OR_upper = exp(estimate + std.error * 1.96)) %>%
  select(term, log_OR, OR, OR_lower, OR_upper, p.value) %>% 
  knitr::kable(digits = 3)
```

| term                   | log\_OR |    OR | OR\_lower | OR\_upper | p.value |
| :--------------------- | ------: | ----: | --------: | --------: | ------: |
| (Intercept)            |   1.186 | 3.274 |     2.067 |     5.186 |   0.000 |
| victim\_age            | \-0.007 | 0.993 |     0.987 |     0.999 |   0.032 |
| victim\_racenon\_white | \-0.820 | 0.441 |     0.313 |     0.620 |   0.000 |
| victim\_sexMale        | \-0.888 | 0.412 |     0.315 |     0.537 |   0.000 |

From the regression, we can find that homicides of non-whites are much
less likely to be solved than white victims. The adjusted odds ratio is
0.453, 95% CI is (0.322, 0.637).

### Run glm for each city

Write function and loop it by may\_df

``` r
func_solving = function(x){
  
city_homicide = df_homicide %>%
  filter(city_state == x) 
  
glm_solving_status = glm(solving_status ~  victim_age + victim_sex + victim_race, data = city_homicide, family = binomial()) 

glm_solving_status %>% 
  broom::tidy() %>% 
  filter(term == "victim_racenon_white") %>%
  mutate(OR = exp(estimate),
         log_OR = estimate,
         OR_lower = exp(estimate - std.error * 1.96),
         OR_upper = exp(estimate + std.error * 1.96)) %>%
  select(term, log_OR，OR, OR_lower, OR_upper, p.value)
}


glm_city = purrr::map_df(.x = unique(df_homicide$city_state), func_solving) %>%
  mutate(term = unique(df_homicide$city_state)) %>%
  select(term, OR, OR_lower, OR_upper)

knitr::kable(glm_city)
```

| term              |        OR | OR\_lower | OR\_upper |
| :---------------- | --------: | --------: | --------: |
| Albuquerque,NM    | 0.7414698 | 0.4512868 | 1.2182443 |
| Atlanta,GA        | 0.7528020 | 0.4315063 | 1.3133316 |
| Baltimore,MD      | 0.4406080 | 0.3129079 | 0.6204234 |
| Baton Rouge,LA    | 0.6676289 | 0.3127439 | 1.4252185 |
| Birmingham,AL     | 1.0392783 | 0.6150483 | 1.7561211 |
| Boston,MA         | 0.1145531 | 0.0471531 | 0.2782939 |
| Buffalo,NY        | 0.3898879 | 0.2127526 | 0.7145036 |
| Charlotte,NC      | 0.5575017 | 0.3207914 | 0.9688794 |
| Chicago,IL        | 0.5620844 | 0.4311321 | 0.7328123 |
| Cincinnati,OH     | 0.3183560 | 0.1839996 | 0.5508195 |
| Columbus,OH       | 0.8547029 | 0.6339868 | 1.1522590 |
| Denver,CO         | 0.6018870 | 0.3589787 | 1.0091626 |
| Detroit,MI        | 0.6512456 | 0.4877782 | 0.8694953 |
| Durham,NC         | 1.0028175 | 0.4041085 | 2.4885469 |
| Fort Worth,TX     | 0.8378356 | 0.5545077 | 1.2659311 |
| Fresno,CA         | 0.4478015 | 0.2306060 | 0.8695617 |
| Houston,TX        | 0.8726047 | 0.6986847 | 1.0898176 |
| Indianapolis,IN   | 0.5045560 | 0.3817941 | 0.6667909 |
| Jacksonville,FL   | 0.6581751 | 0.5023197 | 0.8623880 |
| Las Vegas,NV      | 0.7554159 | 0.5864306 | 0.9730958 |
| Long Beach,CA     | 0.7939031 | 0.3876546 | 1.6258857 |
| Los Angeles,CA    | 0.6658424 | 0.4828459 | 0.9181936 |
| Louisville,KY     | 0.3919136 | 0.2589809 | 0.5930794 |
| Memphis,TN        | 0.7823191 | 0.5238191 | 1.1683866 |
| Miami,FL          | 0.5762370 | 0.3772438 | 0.8801975 |
| Milwaukee,wI      | 0.6323892 | 0.4033912 | 0.9913854 |
| Minneapolis,MN    | 0.6457029 | 0.3447349 | 1.2094287 |
| Nashville,TN      | 0.8985913 | 0.6533730 | 1.2358427 |
| New Orleans,LA    | 0.4659337 | 0.2947205 | 0.7366105 |
| New York,NY       | 0.5314592 | 0.2793572 | 1.0110671 |
| Oakland,CA        | 0.2129779 | 0.1043603 | 0.4346441 |
| Oklahoma City,OK  | 0.6812533 | 0.4780242 | 0.9708841 |
| Omaha,NE          | 0.1689228 | 0.0935132 | 0.3051432 |
| Philadelphia,PA   | 0.6438263 | 0.4862491 | 0.8524692 |
| Pittsburgh,PA     | 0.2815606 | 0.1607457 | 0.4931788 |
| Richmond,VA       | 0.4474146 | 0.1616764 | 1.2381512 |
| San Antonio,TX    | 0.6893496 | 0.4613199 | 1.0300939 |
| Sacramento,CA     | 0.7807364 | 0.4486304 | 1.3586894 |
| Savannah,GA       | 0.5964045 | 0.2800315 | 1.2702083 |
| San Bernardino,CA | 0.8801457 | 0.3928312 | 1.9719832 |
| San Diego,CA      | 0.4833560 | 0.2976277 | 0.7849839 |
| San Francisco,CA  | 0.4582812 | 0.2904504 | 0.7230896 |
| St. Louis,MO      | 0.5770478 | 0.4059333 | 0.8202928 |
| Stockton,CA       | 0.3757201 | 0.1964244 | 0.7186762 |
| Tampa,FL          | 1.1588262 | 0.5870394 | 2.2875435 |
| Tulsa,OK          | 0.6024687 | 0.4130931 | 0.8786605 |
| Washington,DC     | 0.5100815 | 0.2577041 | 1.0096200 |

### Create a plot shows the ORs and CIs

``` r
ggplot(glm_city, aes(x=reorder(term, -OR),y=OR))+
  geom_point() +
  geom_errorbar(aes(ymin = OR_lower, ymax = OR_upper)) +
  geom_hline(yintercept = 1, alpha = 0.4) +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90, hjust = 1), legend.key.width = unit(0.15,'cm')) +
  labs(
    title = "Adjusted OR for homicide resolvation among non-whites and whites by city",
    x = "City, State",
    y = "Adjusted Odds Ratio with 95% CIs"
  )
```

![](p8105_hw6_rh2916_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
  ggtitle('Adjusted Odds Ratio with 95% CIs for each city')
```

    ## $title
    ## [1] "Adjusted Odds Ratio with 95% CIs for each city"
    ## 
    ## $subtitle
    ## NULL
    ## 
    ## attr(,"class")
    ## [1] "labels"

The graph is Adjusted Odds Ratio with 95% CIs for each city in
decreasing OR. From the graph, we can find that Boston,MA has the least
OR while the Tampa,FL has the highest one. Also, except for Tampa,FL,
Durham,NC and Birmingham,AL, all the restcities have OR less than 1,
which shows higher estimate of solving rate of white people than
non-white people.

## Problem 2

### Load and clean the data for regression analysis

``` r
df_birthweight_raw = read.csv("./data/birthweight.csv")

df_birthweight = 
  df_birthweight_raw %>% 
  janitor::clean_names() %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform))

skimr::skim(df_birthweight)
```

    ## Skim summary statistics
    ##  n obs: 4342 
    ##  n variables: 20 
    ## 
    ## -- Variable type:factor -----------------------------------------------------------
    ##  variable missing complete    n n_unique                      top_counts
    ##   babysex       0     4342 4342        2         1: 2230, 2: 2112, NA: 0
    ##     frace       0     4342 4342        5 1: 2123, 2: 1911, 4: 248, 3: 46
    ##   malform       0     4342 4342        2           0: 4327, 1: 15, NA: 0
    ##     mrace       0     4342 4342        4 1: 2147, 2: 1909, 4: 243, 3: 43
    ##  ordered
    ##    FALSE
    ##    FALSE
    ##    FALSE
    ##    FALSE
    ## 
    ## -- Variable type:integer ----------------------------------------------------------
    ##  variable missing complete    n      mean     sd  p0  p25    p50  p75 p100
    ##     bhead       0     4342 4342   33.65     1.62  21   33   34     35   41
    ##   blength       0     4342 4342   49.75     2.72  20   48   50     51   63
    ##       bwt       0     4342 4342 3114.4    512.15 595 2807 3132.5 3459 4791
    ##     delwt       0     4342 4342  145.57    22.21  86  131  143    157  334
    ##   fincome       0     4342 4342   44.11    25.98   0   25   35     65   96
    ##  menarche       0     4342 4342   12.51     1.48   0   12   12     13   19
    ##   mheight       0     4342 4342   63.49     2.66  48   62   63     65   77
    ##    momage       0     4342 4342   20.3      3.88  12   18   20     22   44
    ##    parity       0     4342 4342    0.0023   0.1    0    0    0      0    6
    ##   pnumlbw       0     4342 4342    0        0      0    0    0      0    0
    ##   pnumsga       0     4342 4342    0        0      0    0    0      0    0
    ##      ppwt       0     4342 4342  123.49    20.16  70  110  120    134  287
    ##    wtgain       0     4342 4342   22.08    10.94 -46   15   22     28   89
    ##      hist
    ##  <U+2581><U+2581><U+2581><U+2581><U+2585><U+2587><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2581><U+2581><U+2587><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2583><U+2587><U+2587><U+2582><U+2581>
    ##  <U+2581><U+2587><U+2585><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2581><U+2582><U+2587><U+2582><U+2582><U+2582><U+2581><U+2583>
    ##  <U+2581><U+2581><U+2581><U+2581><U+2582><U+2587><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2585><U+2587><U+2582><U+2581><U+2581>
    ##  <U+2582><U+2587><U+2585><U+2582><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2587><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2587><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2581><U+2587><U+2586><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2581><U+2581><U+2581><U+2587><U+2587><U+2581><U+2581><U+2581>
    ## 
    ## -- Variable type:numeric ----------------------------------------------------------
    ##  variable missing complete    n  mean   sd    p0   p25   p50   p75 p100
    ##   gaweeks       0     4342 4342 39.43 3.15 17.7  38.3  39.9  41.1  51.3
    ##     ppbmi       0     4342 4342 21.57 3.18 13.07 19.53 21.03 22.91 46.1
    ##    smoken       0     4342 4342  4.15 7.41  0     0     0     5    60  
    ##      hist
    ##  <U+2581><U+2581><U+2581><U+2581><U+2583><U+2587><U+2581><U+2581>
    ##  <U+2581><U+2587><U+2585><U+2581><U+2581><U+2581><U+2581><U+2581>
    ##  <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581>

### Propose a regression model for birthweight.

``` r
full_model = lm(bwt ~ ., data = df_birthweight)
summary(full_model)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ ., data = df_birthweight)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1097.68  -184.86    -3.33   173.09  2344.15 
    ## 
    ## Coefficients: (3 not defined because of singularities)
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -6265.3914   660.4011  -9.487  < 2e-16 ***
    ## babysex2       28.7073     8.4652   3.391 0.000702 ***
    ## bhead         130.7781     3.4523  37.881  < 2e-16 ***
    ## blength        74.9536     2.0217  37.075  < 2e-16 ***
    ## delwt           4.1007     0.3948  10.386  < 2e-16 ***
    ## fincome         0.2898     0.1795   1.614 0.106551    
    ## frace2         14.3313    46.1501   0.311 0.756168    
    ## frace3         21.2361    69.2960   0.306 0.759273    
    ## frace4        -46.9962    44.6782  -1.052 0.292912    
    ## frace8          4.2969    74.0741   0.058 0.953745    
    ## gaweeks        11.5494     1.4654   7.882 4.06e-15 ***
    ## malform1        9.7650    70.6259   0.138 0.890039    
    ## menarche       -3.5508     2.8951  -1.226 0.220083    
    ## mheight         9.7874    10.3116   0.949 0.342588    
    ## momage          0.7593     1.2221   0.621 0.534418    
    ## mrace2       -151.4354    46.0453  -3.289 0.001014 ** 
    ## mrace3        -91.3866    71.9190  -1.271 0.203908    
    ## mrace4        -56.4787    45.1369  -1.251 0.210901    
    ## parity         95.5411    40.4793   2.360 0.018307 *  
    ## pnumlbw             NA         NA      NA       NA    
    ## pnumsga             NA         NA      NA       NA    
    ## ppbmi           4.3538    14.8913   0.292 0.770017    
    ## ppwt           -3.4716     2.6121  -1.329 0.183913    
    ## smoken         -4.8544     0.5871  -8.269  < 2e-16 ***
    ## wtgain              NA         NA      NA       NA    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.5 on 4320 degrees of freedom
    ## Multiple R-squared:  0.7183, Adjusted R-squared:  0.717 
    ## F-statistic: 524.6 on 21 and 4320 DF,  p-value: < 2.2e-16

``` r
step_model = step(full_model, direction = "both", trace = FALSE)
summary(step_model)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    ##     gaweeks + mheight + mrace + parity + ppwt + smoken, data = df_birthweight)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1097.18  -185.52    -3.39   174.14  2353.44 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -6098.8219   137.5463 -44.340  < 2e-16 ***
    ## babysex2       28.5580     8.4549   3.378 0.000737 ***
    ## bhead         130.7770     3.4466  37.944  < 2e-16 ***
    ## blength        74.9471     2.0190  37.120  < 2e-16 ***
    ## delwt           4.1067     0.3921  10.475  < 2e-16 ***
    ## fincome         0.3180     0.1747   1.820 0.068844 .  
    ## gaweeks        11.5925     1.4621   7.929 2.79e-15 ***
    ## mheight         6.5940     1.7849   3.694 0.000223 ***
    ## mrace2       -138.7925     9.9071 -14.009  < 2e-16 ***
    ## mrace3        -74.8868    42.3146  -1.770 0.076837 .  
    ## mrace4       -100.6781    19.3247  -5.210 1.98e-07 ***
    ## parity         96.3047    40.3362   2.388 0.017004 *  
    ## ppwt           -2.6756     0.4274  -6.261 4.20e-10 ***
    ## smoken         -4.8434     0.5856  -8.271  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.3 on 4328 degrees of freedom
    ## Multiple R-squared:  0.7181, Adjusted R-squared:  0.7173 
    ## F-statistic: 848.1 on 13 and 4328 DF,  p-value: < 2.2e-16

At first, the model all the possible factors and built model by stepwise
selection. From the summary above, we can find that bhead, babysex,
blength, delwt, gaweeks, wtgain and smoken are significant, so keep
these variables as predictors in the final
model.

### Plot the final model with predictions and residuals

``` r
lm_model = lm(bwt ~ bhead + babysex + blength + delwt + gaweeks + wtgain + smoken, data = df_birthweight)

df_birthweight %>% 
  modelr::add_predictions(lm_model) %>% 
  modelr::add_residuals(lm_model) %>% 
  ggplot(aes(x=pred,y=resid))+
  geom_point(aes(alpha=.2))+
  labs(
    title = "Residuals vs fitted values of birthweight",
    x = "Predictions", y = "Residuals"
  )
```

![](p8105_hw6_rh2916_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

The plot is Residuals vs fitted values of birthweight, from which we can
find that most of the residuals are around 0, but there are some
abnormal values over 1000, which indicates there may be some outliers in
the lower range of birthweight.

### Making two more models

main\_effect\_model contains length at birth and gestational age as
predictors, interaction\_model contains head circumference, length, sex,
and all interactions as predictors

``` r
main_effect_model = lm(bwt ~ blength + gaweeks, data = df_birthweight)
interaction_model = lm(bwt ~ bhead + blength + babysex + bhead * blength * babysex, data = df_birthweight)
```

### Compare my model to two others by Cross-validation

``` r
cv_df = 
  crossv_mc(df_birthweight, 100)

cv_df = cv_df %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(lm_mod = map(train,~lm(bwt ~ bhead + babysex + blength + delwt + gaweeks + wtgain + smoken, data=.x)),
         main_effect_mod = map(train, ~lm(bwt~blength+gaweeks,data=.x)),
         interaction_mod = map(train, ~lm(bwt~bhead + blength + babysex + bhead * blength * babysex, data=.x))) %>% 
  mutate(rmse_lm_mod = map2_dbl(lm_mod,test, ~rmse(model = .x, data=.y)),
         rmse_main_effect_mod = map2_dbl(main_effect_mod,test, ~rmse(model = .x, data=.y)),
         rmse_interaction_mod = map2_dbl(interaction_mod,test, ~rmse(model = .x, data=.y))) 
```

### Make plot of RMSEs

``` r
cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

![](p8105_hw6_rh2916_files/figure-gfm/unnamed-chunk-10-1.png)<!-- -->

From the plot, we can find that compared to The main\_effect\_model, the
lm\_model and interaction\_model have lower rmse and lm\_model is the
best.
